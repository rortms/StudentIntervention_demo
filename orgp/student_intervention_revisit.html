<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>Supervised Learning: Building a Student Intervention System</title>
<!-- 2017-06-18 Sun 17:43 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="Robert M Salom" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center; }
  .todo   { font-family: monospace; color: red; }
  .done   { color: green; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.right  { text-align: center;  }
  th.left   { text-align: center;   }
  th.center { text-align: center; }
  td.right  { text-align: right;  }
  td.left   { text-align: left;   }
  td.center { text-align: center; }
  dt { font-weight: bold; }
  .footpara:nth-child(2) { display: inline; }
  .footpara { display: block; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">Supervised Learning: Building a Student Intervention System</h1>
<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> Obective</h2>
<div class="outline-text-2" id="text-1">
<p>
The goal of this project is to identify students who might need early intervention. We want to predict whether a given student will pass or fail
based on information about his life and habits. Therefore we approach this task as a classification problem with two classes, pass and fail.
</p>
</div>
</div>


<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> Dataset</h2>
<div class="outline-text-2" id="text-2">
<p>
In what follows we will be working with part of the <a href="https://archive.ics.uci.edu/ml/datasets/student+performance">Student Performance Data Set</a> from the UCI machine learning repository. It is composed of
395 data points with 30 attributes each. The 31&rsquo;st attribute indicates whether the student passed or failed. Here is a brief description of
each feature:
</p>
</div>

<div id="outline-container-sec-2-1" class="outline-3">
<h3 id="sec-2-1"><span class="section-number-3">2.1</span> Attributes for student-data.csv:</h3>
<div class="outline-text-3" id="text-2-1">
<ul class="org-ul">
<li>school - student&rsquo;s school (binary: &ldquo;GP&rdquo; or &ldquo;MS&rdquo;)
</li>
<li>sex - student&rsquo;s sex (binary: &ldquo;F&rdquo; - female or &ldquo;M&rdquo; - male)
</li>
<li>age - student&rsquo;s age (numeric: from 15 to 22)
</li>
<li>address - student&rsquo;s home address type (binary: &ldquo;U&rdquo; - urban or &ldquo;R&rdquo; - rural)
</li>
<li>famsize - family size (binary: &ldquo;LE3&rdquo; - less or equal to 3 or &ldquo;GT3&rdquo; - greater than 3)
</li>
<li>Pstatus - parent&rsquo;s cohabitation status (binary: &ldquo;T&rdquo; - living together or &ldquo;A&rdquo; - apart)
</li>
<li>Medu - mother&rsquo;s education (numeric: 0 - none, 1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)
</li>
<li>Fedu - father&rsquo;s education (numeric: 0 - none, 1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)
</li>
<li>Mjob - mother&rsquo;s job (nominal: &ldquo;teacher&rdquo;, &ldquo;health&rdquo; care related, civil &ldquo;services&rdquo; (e.g. administrative or police), &ldquo;at_home&rdquo; or &ldquo;other&rdquo;)
</li>
<li>Fjob - father&rsquo;s job (nominal: &ldquo;teacher&rdquo;, &ldquo;health&rdquo; care related, civil &ldquo;services&rdquo; (e.g. administrative or police), &ldquo;at_home&rdquo; or &ldquo;other&rdquo;)
</li>
<li>reason - reason to choose this school (nominal: close to &ldquo;home&rdquo;, school &ldquo;reputation&rdquo;, &ldquo;course&rdquo; preference or &ldquo;other&rdquo;)
</li>
<li>guardian - student&rsquo;s guardian (nominal: &ldquo;mother&rdquo;, &ldquo;father&rdquo; or &ldquo;other&rdquo;)
</li>
<li>traveltime - home to school travel time (numeric: 1 - &lt;15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - &gt;1 hour)
</li>
<li>studytime - weekly study time (numeric: 1 - &lt;2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - &gt;10 hours)
</li>
<li>failures - number of past class failures (numeric: n if 1&lt;=n&lt;3, else 4)
</li>
<li>schoolsup - extra educational support (binary: yes or no)
</li>
<li>famsup - family educational support (binary: yes or no)
</li>
<li>paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)
</li>
<li>activities - extra-curricular activities (binary: yes or no)
</li>
<li>nursery - attended nursery school (binary: yes or no)
</li>
<li>higher - wants to take higher education (binary: yes or no)
</li>
<li>internet - Internet access at home (binary: yes or no)
</li>
<li>romantic - with a romantic relationship (binary: yes or no)
</li>
<li>famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)
</li>
<li>freetime - free time after school (numeric: from 1 - very low to 5 - very high)
</li>
<li>goout - going out with friends (numeric: from 1 - very low to 5 - very high)
</li>
<li>Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)
</li>
<li>Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)
</li>
<li>health - current health status (numeric: from 1 - very bad to 5 - very good)
</li>
<li>absences - number of school absences (numeric: from 0 to 93)
</li>
<li>passed - did the student pass the final exam (binary: yes or no)
</li>
</ul>
</div>
</div>


<div id="outline-container-sec-2-2" class="outline-3">
<h3 id="sec-2-2"><span class="section-number-3">2.2</span> Loading the data</h3>
<div class="outline-text-3" id="text-2-2">
</div><div id="outline-container-sec-2-2-1" class="outline-4">
<h4 id="sec-2-2-1"><span class="section-number-4">2.2.1</span> Imports</h4>
<div class="outline-text-4" id="text-2-2-1">
<p>
The following python libraries are used in this analysis.
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="color: #0000FF;">import</span> numpy <span style="color: #0000FF;">as</span> np
<span style="color: #0000FF;">import</span> pandas <span style="color: #0000FF;">as</span> pd
<span style="color: #0000FF;">import</span> matplotlib.pyplot <span style="color: #0000FF;">as</span> plt
<span style="color: #0000FF;">from</span> tabulate <span style="color: #0000FF;">import</span> tabulate
<span style="color: #0000FF;">import</span> pickle
</pre>
</div>
</div>
</div>

<div id="outline-container-sec-2-2-2" class="outline-4">
<h4 id="sec-2-2-2"><span class="section-number-4">2.2.2</span> Pre-process</h4>
<div class="outline-text-4" id="text-2-2-2">
<p>
Let us first observe what the graduation rate is for the class;
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #BA36A5;">student_data</span> = pd.read_csv(<span style="color: #008000;">"student-data.csv"</span>)

<span style="color: #BA36A5;">n_students</span> = student_data.shape[0]
<span style="color: #BA36A5;">n_features</span> = student_data.shape[1] - 1
<span style="color: #BA36A5;">n_passed</span> = <span style="color: #006FE0;">sum</span>([1 <span style="color: #0000FF;">for</span> y <span style="color: #0000FF;">in</span> student_data[<span style="color: #008000;">'passed'</span>] <span style="color: #0000FF;">if</span> y == <span style="color: #008000;">'yes'</span>])
<span style="color: #BA36A5;">n_failed</span> = <span style="color: #006FE0;">sum</span>([1 <span style="color: #0000FF;">for</span> n <span style="color: #0000FF;">in</span> student_data[<span style="color: #008000;">'passed'</span>] <span style="color: #0000FF;">if</span> n == <span style="color: #008000;">'no'</span>])
<span style="color: #BA36A5;">grad_rate</span> = 100.*n_passed/(n_passed + n_failed)


tabulate( [[<span style="color: #008000;">"Total number of students: "</span>,n_students],
           [<span style="color: #008000;">"Number of students who passed: "</span>,n_passed],
           [<span style="color: #008000;">"Number of students who failed: "</span>,n_failed],
           [<span style="color: #008000;">"Number of features: "</span>,n_features],
           [<span style="color: #008000;">"Graduation rate of the class:"</span>,  <span style="color: #008000;">"{:.2f}%"</span>.<span style="color: #006FE0;">format</span>(grad_rate)]], tablefmt=<span style="color: #008000;">"grid"</span>)
</pre>
</div>


<p>
This gives us the following figures;
</p>

<!-- This HTML table template is generated by emacs 25.1.1 -->
<table border="1">
  <tr>
    <td align="left" valign="top">
      &nbsp;Total&nbsp;number&nbsp;of&nbsp;students:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;395&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
  </tr>
  <tr>
    <td align="left" valign="top">
      &nbsp;Number&nbsp;of&nbsp;students&nbsp;who&nbsp;passed:&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;265&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
  </tr>
  <tr>
    <td align="left" valign="top">
      &nbsp;Number&nbsp;of&nbsp;students&nbsp;who&nbsp;failed:&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;130&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
  </tr>
  <tr>
    <td align="left" valign="top">
      &nbsp;Number&nbsp;of&nbsp;features:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;30&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
  </tr>
  <tr>
    <td align="left" valign="top">
      &nbsp;Graduation&nbsp;rate&nbsp;of&nbsp;the&nbsp;class:&nbsp;&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;67.09%&nbsp;
    </td>
  </tr>
</table>


<p>
Now we will separate the data into the feature columns and our prediction target, i.e., feature &ldquo;passed&rdquo;.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #BA36A5;">feature_cols</span> = <span style="color: #006FE0;">list</span>(student_data.columns[:-1]) <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">all columns but last are features</span>
<span style="color: #BA36A5;">target_col</span> = student_data.columns[-1]          <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">last column is the target/label</span>

<span style="color: #BA36A5;">X_all</span> = student_data[feature_cols]             <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">feature values for all students</span>
<span style="color: #BA36A5;">y_all</span> = student_data[target_col]               <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">corresponding targets/labels</span>
</pre>
</div>


<p>
Addiontally, we must transform all categorical features into binary/numeric ones in order to be processed
by subsequent algorithms. Pandas&rsquo; <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies">get_dummies</a> function will come in handy.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #0000FF;">def</span> <span style="color: #006699;">preprocess_features</span>(X):
    <span style="color: #BA36A5;">outX</span> = pd.DataFrame(index=X.index)  <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">output dataframe, initially empty</span>
    <span style="color: #8D8D84;">#</span>
    <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Check each column</span>
    <span style="color: #0000FF;">for</span> col, col_data <span style="color: #0000FF;">in</span> X.iteritems():
        <span style="color: #8D8D84;">#</span>
        <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Change the data type for yes/no columns to int</span>
        <span style="color: #0000FF;">if</span> col_data.dtype == <span style="color: #006FE0;">object</span>:
            <span style="color: #BA36A5;">col_data</span> = col_data.replace([<span style="color: #008000;">'yes'</span>, <span style="color: #008000;">'no'</span>], [1, 0])
        <span style="color: #8D8D84;">#</span>
        <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">For other categories convert to one or more dummy variables</span>
        <span style="color: #0000FF;">if</span> col_data.dtype == <span style="color: #006FE0;">object</span>:
            <span style="color: #BA36A5;">col_data</span> = pd.get_dummies(col_data, prefix=col)  <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">e.g. 'school' =&gt; 'school_GP', 'school_MS'</span>
        <span style="color: #8D8D84;">#    </span>
        <span style="color: #BA36A5;">outX</span> = outX.join(col_data)  <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">collect column(s) in output dataframe</span>
    <span style="color: #0000FF;">return</span> outX
</pre>
</div>


<div class="org-src-container">

<pre class="src src-python"><span style="color: #BA36A5;">X_all</span> = preprocess_features(X_all)
</pre>
</div>

<p>
Now we are ready to split the data into training and test sets. Approximately 75% of the data will be used
for training. This will leave  300 training samples and 95 test samples. We will employ Sci-kit learn&rsquo;s 
train_test_split function to perform the data split.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #0000FF;">from</span> sklearn.model_selection <span style="color: #0000FF;">import</span> train_test_split
<span style="color: #BA36A5;">X_train</span>, <span style="color: #BA36A5;">X_test</span>, <span style="color: #BA36A5;">y_train</span>, <span style="color: #BA36A5;">y_test</span> = train_test_split(
    X_all, y_all, test_size = .24, random_state = 0)
<span style="color: #8D8D84;">#</span>
<span style="color: #8D8D84;">#</span>
<span style="color: #036A07;">"Training set: {} samples"</span>.<span style="color: #006FE0;">format</span>(X_train.shape[0]), <span style="color: #036A07;">"Test set: {} samples"</span>.<span style="color: #006FE0;">format</span>(X_test.shape[0])
</pre>
</div>
</div>
</div>
</div>


<div id="outline-container-sec-2-3" class="outline-3">
<h3 id="sec-2-3"><span class="section-number-3">2.3</span> Data Exploration</h3>
<div class="outline-text-3" id="text-2-3">
<p>
To identify whether it is appropriate to treat the data under a single model, that is, to identify whether its a manifold of multiple charts or
a single chart, we employ a <a href="http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html">t-sne</a> projection. We&rsquo;ll project to 2-dimensions with red labeling failed and blue labeling passing data points.
This may or may not reveal some intrinsic clustering relative to our feature of interest &lsquo;passed&rsquo;. It is recommended for t-sne to be fed features
scaled to simlar ranges, so this is the first pre-process step. 
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #0000FF;">from</span> sklearn.preprocessing <span style="color: #0000FF;">import</span> MinMaxScaler
<span style="color: #8D8D84;">#</span>
<span style="color: #BA36A5;">scaler</span> = MinMaxScaler()
<span style="color: #BA36A5;">uX_all</span> = scaler.fit_transform(X_all)
</pre>
</div>

<p>
Since our data set is not large we can indulge in the exact t-sne algorithm instead of the speedier &lsquo;barnes-hut&rsquo;.
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="color: #0000FF;">from</span> sklearn.manifold <span style="color: #0000FF;">import</span> TSNE
<span style="color: #8D8D84;">#</span>
<span style="color: #BA36A5;">model</span> = TSNE(n_components=2,
             early_exaggeration=4.0,
             learning_rate=1000,
             n_iter=1000,
             init=<span style="color: #008000;">'pca'</span>,
             random_state=0,
             method=<span style="color: #008000;">'exact'</span>)
<span style="color: #8D8D84;">#</span>
<span style="color: #BA36A5;">clusters</span> = model.fit_transform(uX_all)
</pre>
</div>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Painting cluster data according to pass or fail</span>
<span style="color: #BA36A5;">x_fail</span>, <span style="color: #BA36A5;">y_fail</span> = <span style="color: #006FE0;">zip</span>(*[ <span style="color: #006FE0;">tuple</span>(pt) <span style="color: #0000FF;">for</span> i, pt <span style="color: #0000FF;">in</span> <span style="color: #006FE0;">enumerate</span>(clusters) <span style="color: #0000FF;">if</span> y_all[i] == <span style="color: #008000;">'no'</span>])
<span style="color: #BA36A5;">x_pass</span>, <span style="color: #BA36A5;">y_pass</span> = <span style="color: #006FE0;">zip</span>(*[ <span style="color: #006FE0;">tuple</span>(pt) <span style="color: #0000FF;">for</span> i, pt <span style="color: #0000FF;">in</span> <span style="color: #006FE0;">enumerate</span>(clusters) <span style="color: #0000FF;">if</span> y_all[i] == <span style="color: #008000;">'yes'</span>])
<span style="color: #8D8D84;">#</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Build plot</span>
<span style="color: #BA36A5;">ax</span> = plt.subplot(111)
ax.scatter(x_fail, y_fail, s=50, c=<span style="color: #008000;">'red'</span>, alpha=0.5, label=<span style="color: #008000;">"student failed"</span>)
ax.scatter(x_pass, y_pass, s=50, c=<span style="color: #008000;">'blue'</span>, alpha=0.5, label=<span style="color: #008000;">"student passed"</span>)
<span style="color: #8D8D84;">#</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Saving</span>
plt.savefig(<span style="color: #008000;">"./figures/t-sne_all.png"</span>)
</pre>
</div>



<div id="T-SNE-All" class="figure">
<p><img src="./figures/t-sne_all.png" alt="t-sne_all.png" />
</p>
<p><span class="figure-number">Figure 1:</span> T-SNE 2-d projection all sample points</p>
</div>

<p>
T-SNE reveals no obvious clustering of the data itself, nor of its pass/fail labeling. We will treat the data under a single model.
</p>
</div>
</div>
</div>


<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> Training and Evaluating Models</h2>
<div class="outline-text-2" id="text-3">
</div><div id="outline-container-sec-3-1" class="outline-3">
<h3 id="sec-3-1"><span class="section-number-3">3.1</span> Baseline Performance</h3>
<div class="outline-text-3" id="text-3-1">
<p>
After an analysis of several algorithms, the details of which can be found <a href="https://github.com/rortms/Udacity_Machine/blob/master/P2/student_intervention/Final_Report.pdf">here</a>, we will proceed with
the binary classification using a DecisionTree classifier and a K-neighbors classifier for reference.
</p>

<p>
Kfold cross validation can be used to get the maximum use of a small data set like the one here. We 
apply Kfold cross-validation on the training set with 10 folds to have a basic handle on how the models
perform out of the box. 
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #0000FF;">from</span> sklearn.tree <span style="color: #0000FF;">import</span> DecisionTreeClassifier
<span style="color: #0000FF;">from</span> sklearn.neighbors <span style="color: #0000FF;">import</span> KNeighborsClassifier
<span style="color: #8D8D84;">#</span>
<span style="color: #0000FF;">from</span> sklearn.cross_validation <span style="color: #0000FF;">import</span> KFold
<span style="color: #8D8D84;">#</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Setting up KFold cross_validation object</span>
<span style="color: #BA36A5;">kf</span> = KFold(X_train.shape[0], 10)
<span style="color: #8D8D84;">#</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Array of classifiers</span>
<span style="color: #BA36A5;">clfs</span> = [DecisionTreeClassifier(criterion = <span style="color: #008000;">"entropy"</span>),
        KNeighborsClassifier(n_neighbors = 3)]
<span style="color: #8D8D84;"># </span>
<span style="color: #8D8D84;">#</span><span style="color: #8D8D84; font-style: italic;">Gathering Table column and index labels</span>
<span style="color: #BA36A5;">classifier_names</span> = [clf.__class__.<span style="color: #006FE0;">__name__</span> <span style="color: #0000FF;">for</span> clf <span style="color: #0000FF;">in</span> clfs]
<span style="color: #BA36A5;">benchmarks</span> = [<span style="color: #008000;">"Training time"</span>,  <span style="color: #008000;">"F1 score training set"</span>,<span style="color: #008000;">"Prediction time"</span>, <span style="color: #008000;">"F1 score test set"</span>]
<span style="color: #BA36A5;">table</span> = pd.DataFrame(columns = classifier_names, index = benchmarks)
<span style="color: #8D8D84;">#</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Fit Classifiers and average the times and f1 scores resulting from KFold (10 folds)</span>
<span style="color: #0000FF;">for</span> clf <span style="color: #0000FF;">in</span> clfs: 
    <span style="color: #BA36A5;">classifier</span>   = clf.__class__.<span style="color: #006FE0;">__name__</span>
    <span style="color: #BA36A5;">t_test</span>  = 0.0 
    <span style="color: #BA36A5;">t_train</span> = 0.0
    <span style="color: #BA36A5;">F1_test</span> = 0.0
    <span style="color: #BA36A5;">F1_train</span> =0.0
    <span style="color: #8D8D84;">#</span>
    <span style="color: #8D8D84;">#</span><span style="color: #8D8D84; font-style: italic;">Averaging scores and seconds accross the folds</span>
    <span style="color: #0000FF;">for</span> tr_i ,t_i <span style="color: #0000FF;">in</span> kf:
        <span style="color: #8D8D84;">#</span><span style="color: #8D8D84; font-style: italic;">Train (k-1 buckets)</span>
        <span style="color: #BA36A5;">t_train</span> += timeTraining(clf, X_train.iloc[tr_i], y_train.iloc[tr_i])
        <span style="color: #BA36A5;">pred_train_set</span> = predictAndTime(clf, X_train.iloc[tr_i])[0]
        <span style="color: #BA36A5;">F1_train</span> += F1(y_train.iloc[tr_i], pred_train_set)
        <span style="color: #8D8D84;">#</span><span style="color: #8D8D84; font-style: italic;">Test (kth bucket)</span>
        <span style="color: #BA36A5;">pred_test_set</span>, <span style="color: #BA36A5;">t_t</span> = predictAndTime(clf,X_train.iloc[t_i])
        <span style="color: #BA36A5;">t_test</span> += t_t
        <span style="color: #BA36A5;">F1_test</span> += F1(y_train.iloc[t_i], pred_test_set)
    <span style="color: #8D8D84;">#   </span>
    <span style="color: #8D8D84;">#</span><span style="color: #8D8D84; font-style: italic;">Filling table </span>
    table[classifier][<span style="color: #008000;">'Training time'</span>]         = <span style="color: #008000;">"{:10.4f} s"</span>.<span style="color: #006FE0;">format</span>(t_train/10)
    table[classifier][<span style="color: #008000;">'F1 score training set'</span>] = F1_train/10
    table[classifier][<span style="color: #008000;">'Prediction time'</span>]       = <span style="color: #008000;">"{:10.4f} s"</span>.<span style="color: #006FE0;">format</span>(t_test/10)
    table[classifier][<span style="color: #008000;">'F1 score test set'</span>]     = F1_test/10
</pre>
</div>

<!-- This HTML table template is generated by emacs 25.1.1 -->
<table border="1">
  <tr>
    <td align="left" valign="top">
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;DecisionTreeClassifier&nbsp;&nbsp;&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;KNeighborsClassifier&nbsp;&nbsp;&nbsp;
    </td>
  </tr>
  <tr>
    <td align="left" valign="top">
      &nbsp;Training&nbsp;time&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;0.0060&nbsp;s&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;0.0008&nbsp;s&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
  </tr>
  <tr>
    <td align="left" valign="top">
      &nbsp;F1&nbsp;score&nbsp;training&nbsp;set&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;1.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;0.889300900467&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
  </tr>
  <tr>
    <td align="left" valign="top">
      &nbsp;Prediction&nbsp;time&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;0.0003&nbsp;s&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;0.0018&nbsp;s&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
  </tr>
  <tr>
    <td align="left" valign="top">
      &nbsp;F1&nbsp;score&nbsp;test&nbsp;set&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;0.708666825808&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;0.780716646689&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
  </tr>
</table>

<p>
The results above show that the tree scores perfectly on the training set and it&rsquo;s outperformed by KNN on the test set,
with 0.709 to KNN&rsquo;s .781. The tree is most likely overfitting. We will tune both models with a grid search.
</p>
</div>
</div>

<div id="outline-container-sec-3-2" class="outline-3">
<h3 id="sec-3-2"><span class="section-number-3">3.2</span> Gridsearch Tuning</h3>
<div class="outline-text-3" id="text-3-2">
<div class="org-src-container">

<pre class="src src-python"><span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Imports</span>
<span style="color: #0000FF;">from</span> sklearn <span style="color: #0000FF;">import</span> grid_search
<span style="color: #0000FF;">from</span> sklearn.metrics <span style="color: #0000FF;">import</span> make_scorer
<span style="color: #8D8D84;">#</span>
<span style="color: #BA36A5;">scorer</span> = make_scorer(F1)
<span style="color: #8D8D84;">#</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">GridSearch parameters for Tree</span>
<span style="color: #BA36A5;">tree_param</span> = { <span style="color: #008000;">'n_estimators'</span> : <span style="color: #006FE0;">range</span>(2,7),<span style="color: #008000;">'criterion'</span>: [<span style="color: #008000;">"entropy"</span>, <span style="color: #008000;">"gini"</span>], <span style="color: #008000;">'max_features'</span>:[<span style="color: #008000;">"sqrt"</span>, <span style="color: #008000;">"log2"</span>], <span style="color: #008000;">'max_depth'</span>: <span style="color: #006FE0;">range</span>(2,11),
               <span style="color: #008000;">'min_samples_split'</span>:<span style="color: #006FE0;">range</span>(2,9), <span style="color: #008000;">'min_samples_leaf'</span>:<span style="color: #006FE0;">range</span>(1,9) }
<span style="color: #8D8D84;">#</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Gridsearch parameters for KNN</span>
<span style="color: #BA36A5;">neigh_param</span> = {<span style="color: #008000;">'n_neighbors'</span> : [3,5,10,20,25,30,40], <span style="color: #008000;">'weights'</span> : [<span style="color: #008000;">'uniform'</span>, <span style="color: #008000;">'distance'</span>], <span style="color: #008000;">'p'</span>:[1,2,3,5,10],
               <span style="color: #008000;">'algorithm'</span> : [<span style="color: #008000;">'ball_tree'</span>, <span style="color: #008000;">'kd_tree'</span>, <span style="color: #008000;">'brute'</span>]}
<span style="color: #8D8D84;">#</span>
<span style="color: #8D8D84;">#</span><span style="color: #8D8D84; font-style: italic;">Perform grid Search</span>
<span style="color: #0000FF;">def</span> <span style="color: #006699;">gridIt</span>(clf, params):
    <span style="color: #8D8D84;">#</span><span style="color: #8D8D84; font-style: italic;">Grid search folds = 10, for consistency with previous computations</span>
    <span style="color: #BA36A5;">grid_clf</span> = grid_search.GridSearchCV(clf, params,
                                        scorer, n_jobs=4, cv = 10)
    <span style="color: #0000FF;">print</span> clf.__class__.<span style="color: #006FE0;">__name__</span>
    <span style="color: #0000FF;">print</span> <span style="color: #008000;">"Grid search time:"</span>, timeTraining(grid_clf, X_train, y_train)
    <span style="color: #0000FF;">print</span> <span style="color: #008000;">"Parameters of tuned model: "</span>, grid_clf.best_params_
    <span style="color: #BA36A5;">y_pred</span>, <span style="color: #BA36A5;">predict_t</span> = predictAndTime(grid_clf, X_test)
    <span style="color: #0000FF;">print</span> <span style="color: #008000;">"f1_score and prediction time on X_test, y_test: "</span>
    <span style="color: #0000FF;">print</span> F1(y_test, y_pred), predict_t
    <span style="color: #0000FF;">print</span> <span style="color: #008000;">'------------------\n'</span>

<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">gridIt(KNeighborsClassifier(), neigh_param)</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">gridIt(RandomForestClassifier(), tree_param)</span>
</pre>
</div>
</div>
</div>
</div>
</div>
</body>
</html>
