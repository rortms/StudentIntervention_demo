{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Supervised Learning: Building a Student Intervention System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Objective\n",
    "\n",
    "The goal of this project is to identify students who might need early intervention. We want to predict whether a given student will pass or\n",
    "fail based on information about his life and habits. Therefore we approach this task as a classification problem with two classes, pass and fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Reading the data\n",
    "\n",
    "In what follows we will be working with part of the [_Student Performance Data set_](https://archive.ics.uci.edu/ml/datasets/student+performance)\n",
    "dataset from the UCI machine learning repository. It is composed of 395 data points with 30 attributes each. The 31'st attribute indicates whether\n",
    "the student passed or failed. Here is a brief description of each feature:\n",
    "\n",
    "Attributes for student-data.csv:\n",
    "\n",
    " * school - student's school (binary: \"GP\" or \"MS\")\n",
    " * sex - student's sex (binary: \"F\" - female or \"M\" - male)\n",
    " * age - student's age (numeric: from 15 to 22)\n",
    " * address - student's home address type (binary: \"U\" - urban or \"R\" - rural)\n",
    " * famsize - family size (binary: \"LE3\" - less or equal to 3 or \"GT3\" - greater than 3)\n",
    " * Pstatus - parent's cohabitation status (binary: \"T\" - living together or \"A\" - apart)\n",
    " * Medu - mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)\n",
    " * Fedu - father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)\n",
    " * Mjob - mother's job (nominal: \"teacher\", \"health\" care related, civil \"services\" (e.g. administrative or police), \"at_home\" or \"other\")\n",
    " * Fjob - father's job (nominal: \"teacher\", \"health\" care related, civil \"services\" (e.g. administrative or police), \"at_home\" or \"other\")\n",
    " * reason - reason to choose this school (nominal: close to \"home\", school \"reputation\", \"course\" preference or \"other\")\n",
    " * guardian - student's guardian (nominal: \"mother\", \"father\" or \"other\")\n",
    " * traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n",
    " * studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n",
    " * failures - number of past class failures (numeric: n if 1<=n<3, else 4)\n",
    " * schoolsup - extra educational support (binary: yes or no)\n",
    " * famsup - family educational support (binary: yes or no)\n",
    " * paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n",
    " * activities - extra-curricular activities (binary: yes or no)\n",
    " * nursery - attended nursery school (binary: yes or no)\n",
    " * higher - wants to take higher education (binary: yes or no)\n",
    " * internet - Internet access at home (binary: yes or no)\n",
    " * romantic - with a romantic relationship (binary: yes or no)\n",
    " * famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n",
    " * freetime - free time after school (numeric: from 1 - very low to 5 - very high)\n",
    " * goout - going out with friends (numeric: from 1 - very low to 5 - very high)\n",
    " * Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    " * Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    " * health - current health status (numeric: from 1 - very bad to 5 - very good)\n",
    " * absences - number of school absences (numeric: from 0 to 93)\n",
    " * passed - did the student pass the final exam (binary: yes or no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Read student data\n",
    "student_data = pd.read_csv(\"student-data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We explore the following features in the data:\n",
    "\n",
    " * Total number of students\n",
    " * Number of students who passed\n",
    " * Number of students who failed\n",
    " * Graduation rate of the class (%)\n",
    " * Number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of students: 395\n",
      "Number of students who passed: 265\n",
      "Number of students who failed: 130\n",
      "Number of features: 30\n",
      "Graduation rate of the class: 67.09%\n"
     ]
    }
   ],
   "source": [
    "n_students = student_data.shape[0]\n",
    "n_features = student_data.shape[1] - 1\n",
    "n_passed = sum([1 for y in student_data['passed'] if y == 'yes'])\n",
    "n_failed = sum([1 for n in student_data['passed'] if n == 'no'])\n",
    "grad_rate = 100.*n_passed/(n_passed + n_failed)\n",
    "\n",
    "print \"Total number of students: {}\".format(n_students)\n",
    "print \"Number of students who passed: {}\".format(n_passed)\n",
    "print \"Number of students who failed: {}\".format(n_failed)\n",
    "print \"Number of features: {}\".format(n_features)\n",
    "print \"Graduation rate of the class: {:.2f}%\".format(grad_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Preparing the Data\n",
    "In this section, we will prepare the data for modeling, training and testing.\n",
    "\n",
    "### Identify feature and target columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature column(s):-\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "Target column: passed\n",
      "\n",
      "Feature values:-\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract feature (X) and target (y) columns\n",
    "feature_cols = list(student_data.columns[:-1])  # all columns but last are features\n",
    "target_col = student_data.columns[-1]  # last column is the target/label\n",
    "print \"Feature column(s):-\\n{}\".format(feature_cols)\n",
    "print \"Target column: {}\".format(target_col)\n",
    "\n",
    "X_all = student_data[feature_cols]  # feature values for all students\n",
    "y_all = student_data[target_col]  # corresponding targets/labels\n",
    "print \"\\nFeature values:-\"\n",
    "print X_all.head()  # print the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Preprocess feature columns\n",
    "\n",
    "As you can see, there are several non-numeric columns that need to be converted. Many of them are simply `yes`/`no`, e.g. `internet`. These can\n",
    "be reasonably converted into `1`/`0` (binary) values.\n",
    "\n",
    "Other columns, like `Mjob` and `Fjob`, have more than two values, and are known as _categorical variables_. The recommended way to handle such\n",
    "a column is to create as many columns as possible values (e.g. `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc.), and assign a `1` to one of\n",
    "them and `0` to all others.\n",
    "\n",
    "These generated columns are sometimes called _dummy variables_, and we will use the\n",
    "[`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies)\n",
    "function to perform this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48):-\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "# Preprocess feature columns\n",
    "def preprocess_features(X):\n",
    "    outX = pd.DataFrame(index=X.index)  # output dataframe, initially empty\n",
    "\n",
    "    # Check each column\n",
    "    for col, col_data in X.iteritems():\n",
    "        # If data type is non-numeric, try to replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "        # Note: This should change the data type for yes/no columns to int\n",
    "\n",
    "        # If still non-numeric, convert to one or more dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix=col)  # e.g. 'school' => 'school_GP', 'school_MS'\n",
    "\n",
    "        outX = outX.join(col_data)  # collect column(s) in output dataframe\n",
    "\n",
    "    return outX\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print \"Processed feature columns ({}):-\\n{}\".format(len(X_all.columns), list(X_all.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Split data into training and test sets\n",
    "\n",
    "So far, we have converted all _categorical_ features into numeric values. In this next step, we split the data (both features and corresponding\n",
    "labels) into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 300 samples\n",
      "Test set: 95 samples\n"
     ]
    }
   ],
   "source": [
    "# First, decide how many training vs test samples you want\n",
    "num_all = student_data.shape[0]  # same as len(student_data)\n",
    "num_train = 300  # about 75% of the data\n",
    "num_test = num_all - num_train\n",
    "\n",
    "# TODO: Then, select features (X) and corresponding labels (y) for the training and test sets\n",
    "# Note: Shuffle the data or randomly select samples to avoid any bias due to ordering in the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size = .24, random_state = 0)\n",
    "\n",
    "print \"Training set: {} samples\".format(X_train.shape[0])\n",
    "print \"Test set: {} samples\".format(X_test.shape[0])\n",
    "# Note: If you need a validation set, extract it from within training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## 4. Training and Evaluating Models\n",
    "Next we perform a baseline comparison of 5 different classification models out of the box.\n",
    "\n",
    " - DecisionTreeClassifier\n",
    " - SVC\n",
    " - KNeighborsClassifier\n",
    " - GaussianNB\n",
    " - AdaBoostClassifier\n",
    "\n",
    "We fit the model to the training data, try to predict labels (for both training and test sets), and measure the F<sub>1</sub> score. Then\n",
    "repeat this process with different training set sizes (100, 200, 300), keeping test set constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* * *\n",
    "**Model Training**  \n",
    "\n",
    "Kfold cross validation can be used to get the maximum use of a small data set like the one here. To get my bearings and not to impose any\n",
    "pre-judgement, I wanted to try most of the classifiers seen in class out of the box. I excluded neural net, since its recommended use requires\n",
    "the features to be scaled (one of the disadvantages of that algorithm).  After separating the data into a training set (size 300) and test set\n",
    "(size 95), I used Kfold cross-validation on the training set with 10 folds to have a basic handle on how the models were performing on\n",
    "average. The result of this can be seen in the table below. The decision tree trails all others in its f1 test score, while scoring perfectly\n",
    "on the training set (which no other does) so it seems to be over-fitting.  The SVC tops all others with an average test f1 of 0.808. KNN\n",
    "doesn't trail far with 0.781. Naive Bayes and AdaBoost are pretty much tied with test f1's of 0.768 and 0.767 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "import time\n",
    "from IPython.display import display, HTML \n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Return the classifier's training time\n",
    "def timeTraining(clf, X_train, y_train):\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    return (end - start)\n",
    "\n",
    "# Return the classifier's predictions and prediction time\n",
    "def predictAndTime(clf, features):\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    return y_pred, (end - start)\n",
    "\n",
    "# Return the f1 score for the target values and predictions\n",
    "def F1(target, prediction):\n",
    "    return f1_score(target.values, prediction, pos_label='yes')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      DecisionTreeClassifier           SVC    GaussianNB  \\\nTraining time                       0.0030 s      0.0066 s      0.0010 s   \nF1 score training set                      1      0.874614      0.799737   \nPrediction time                     0.0002 s      0.0007 s      0.0003 s   \nF1 score test set                   0.694455      0.807571      0.767603   \n\n                      AdaBoostClassifier KNeighborsClassifier  \nTraining time                   0.1336 s             0.0008 s  \nF1 score training set           0.870058             0.889301  \nPrediction time                 0.0049 s             0.0017 s  \nF1 score test set                0.76675             0.780717  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Adding Kfold validation to try out the Pro Tip from CodeReview2\n",
    "from sklearn.cross_validation import KFold  \n",
    "\n",
    "# Setting up KFold cross_validation object\n",
    "kf = KFold(X_train.shape[0], 10)\n",
    "\n",
    "# Array of classifiers\n",
    "clfs = [DecisionTreeClassifier(criterion = \"entropy\"),\n",
    "        SVC(C = 1.0, kernel=\"rbf\"),\n",
    "        GaussianNB(),\n",
    "        AdaBoostClassifier(),\n",
    "        KNeighborsClassifier(n_neighbors = 3)]\n",
    " \n",
    "#Gathering Table column and index labels\n",
    "classifier_names = [clf.__class__.__name__ for clf in clfs]\n",
    "benchmarks = [\"Training time\",  \"F1 score training set\",\"Prediction time\", \"F1 score test set\"]\n",
    "table = pd.DataFrame(columns = classifier_names, index = benchmarks)\n",
    "\n",
    "# Fit Classifiers and average the times and f1 scores resulting from KFold (10 folds)\n",
    "for clf in clfs: \n",
    "    classifier   = clf.__class__.__name__\n",
    "    t_test  = 0.0 \n",
    "    t_train = 0.0\n",
    "    F1_test = 0.0\n",
    "    F1_train =0.0\n",
    "    \n",
    "    #Averaging scores and seconds accross the folds\n",
    "    for tr_i ,t_i in kf:\n",
    "        #Train (k-1 buckets)\n",
    "        t_train += timeTraining(clf, X_train.iloc[tr_i], y_train.iloc[tr_i])\n",
    "        pred_train_set = predictAndTime(clf, X_train.iloc[tr_i])[0]\n",
    "        F1_train += F1(y_train.iloc[tr_i], pred_train_set)\n",
    "        #Test (kth bucket)\n",
    "        pred_test_set, t_t = predictAndTime(clf,X_train.iloc[t_i])\n",
    "        t_test += t_t\n",
    "        F1_test += F1(y_train.iloc[t_i], pred_test_set)\n",
    "        \n",
    "    #Filling table \n",
    "    table[classifier]['Training time']         = \"{:10.4f} s\".format(t_train/10)\n",
    "    table[classifier]['F1 score training set'] = F1_train/10\n",
    "    table[classifier]['Prediction time']       = \"{:10.4f} s\".format(t_test/10)\n",
    "    table[classifier]['F1 score test set']     = F1_test/10\n",
    "    \n",
    "from IPython.display import display, HTML  \n",
    "display(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "__DecisionTree:__ Generates a tree representation of a decision function, where each node in the tree represents an if-then-else decision rule,\n",
    "and each leaf finally places the input in a given category (pass/fail in our case).\n",
    "\n",
    "__Pros:__  \n",
    "\n",
    "* Simple to understand and interpret. The decision function can explicitly be drawn out as a tree structure.  \n",
    "\n",
    "* The cost of predicting is logarithmic on the size of the training data.  \n",
    "\n",
    "* It can handle categorical and numerical data equally well.  \n",
    "\n",
    "__Cons:__\n",
    "\n",
    "* They are prone to overffiting the data (as can be seen in the table) unless pruned, and/or tuned through its various paramters (i.e. minimum samples per leaf, maximum depth). This can be costly.  \n",
    "\n",
    "* They can be unstable; small variations in the data can generate completely different trees.  \n",
    "\n",
    "* They can create bias trees if some classes dominate.  \n",
    "\n",
    "__Chosen/rejected:__ Chosen  \n",
    "\n",
    "__Reasoning:__ Before we manipulated it, the data was strongly categorical. Even age, though ordered, basically could be thought of as buckets\n",
    "between 15 and 22.  Even though the decision tree can handle both categorical and numerical data equally well, overall the structure of this\n",
    "data seems like a good fit for the tree like decision function. We can easily see how if then rules can be deduced from the attributes, things\n",
    "like, if (has internet connection) then … , or if (father's job == Teacher) then … else if (father's job == Healthcare worker) then … , so on\n",
    "and so forth. The data is also not too badly out of balance (approx 2:1 pass to no pass ratio) which mitigates one of the cons. Tunning the\n",
    "tree to improve its performance may prove costly and there is already some evidence of overfitting above. Using the model for prediction is\n",
    "fast, which would be advantageous in a situation of limited computational resources.\n",
    "\n",
    "* * *  \n",
    "\n",
    "__SVC:__ Seeks to maximize the decision boundary between classes by solving a quadratic programming problem.  \n",
    "\n",
    "__Pros:__ \n",
    "\n",
    "* Effective for data with a high number of attributes  \n",
    "\n",
    "* Still effective when there are more attributes than data points  \n",
    "\n",
    "* Its memory efficient because only a subset of the data is required (support vectors)  \n",
    "\n",
    "* Highly tunable at the tuning phase (also a con). In sklearn's implementation we have 4 kernel function (plus the ability to define a custom\n",
    "  kernel) plus around a dozen parameters.\n",
    "\n",
    "__Cons:__  \n",
    "\n",
    "* Harder to conceptualize relative to other models. The entire mechanism of the algorithm is a rather abstract linear algebra/analysis\n",
    "  problem. (Though this con only really applies when seeking to interpret results in an intuitive way)\n",
    "\n",
    "* Though both its training time and predcition time were relatively fast out of the box, the model can be costly to tune do to its sheer number\n",
    "  of configurations (can also be a pro).\n",
    "\n",
    "* Can only expensively provide probability estimates. (Not so relevant here) \n",
    "\n",
    "__Chosen/Rejected:__ Chosen  \n",
    "\n",
    "__Reasoning:__ For this particular problem since we are not required to estimate any probabilties there seems to be little downside to using\n",
    "SVC. On the other hand, some of its strengths are also not particulary relevant since, the number of attributes is pretty small compared to the\n",
    "size of our data set. Its memory efficiency definitely fits within a scenario were we have small reasorces. Its f1 score on the test set was\n",
    "also best out of all, out of the box.\n",
    "\n",
    "* * *  \n",
    "\n",
    "__GaussianNB:__ Applies Baye's theorem with the assumption of independence between every pair of attributes. From the training data it\n",
    "calculates particular P(__x__|y)'s (i.e. given a label what is the probability of the input point __x__) fits them to a Gaussian\n",
    "distribution. It then uses that model, applying Bayes, to approximate P(y|__x__) for new inputs __x__.\n",
    "\n",
    "__Pros:__  \n",
    "\n",
    "* Requires only a small amount of training data to estimate the necessary parameters. \n",
    "\n",
    "* They can be very fast compared to more sophisticated methods (evidence of this can be seen in the table)  \n",
    "\n",
    "__Cons:__  \n",
    "\n",
    "*  Bad estimator of probabilities. (Not so relevant here)  \n",
    "\n",
    "* Sklearn's implementation has little in the way of tune-ability.  \n",
    "\n",
    "__Chosen/Rejected:__ Rejected  \n",
    "\n",
    "__Reasoning:__ GaussianNB was one of the fastest to be trained and had a decent average f1 test score. Two of Naive Bayes' advantages that are\n",
    "relevant to this problem are, its capacity to train on small amounts of data and its training speed. In this sense it is perfectly suited for\n",
    "the situation at hand. The main reason I pass on it, is the lack of tune-able parameters in sklearn's GaussianNB implementation. So I don't\n",
    "have a real chance of improving its performance from here, what I see now is what I get (I maybe wrong on this).\n",
    "\n",
    "* * * \n",
    "\n",
    "__AdaBoostClassifier:__ It trains multiple weak classifiers (weak meaning they are better than guessing i.e. generalization error < 0.5), and\n",
    "then combines them into a single boosted classifier using a weighted voting scheme.\n",
    "\n",
    "__Pros:__  \n",
    "\n",
    "* Computationally efficient (taken from Intro to boosting pdf)  \n",
    "\n",
    "* No difficult parameters to set  \n",
    "\n",
    "* Versatile – a wide range of weak learners can be used  \n",
    "\n",
    "__Cons:__  \n",
    "\n",
    "* Weak learner should not be too complex to avoid overffiting  \n",
    "\n",
    "* There needs to be enough data so that the weak learner requirement is satisfied.  \n",
    "\n",
    "__Chosen/Rejected:__ Rejected  \n",
    "\n",
    "__Reasoning:__ From the above table, AdaBoost seems expensive to train as its average training time of 0.1022s is approximately 15 times slower\n",
    "than the next slowest time of 0.069s by SVC. Also from the Intro to Boosting reading, it seems that choosing the weak learner properly is\n",
    "particularly important for this algorithm to perform well. Simply using the default DecisionTree weak learner from sklearn's implementation,\n",
    "resulted in the somewhat costly, and not particularly strong performance seen in the table above. I experimented briefly using grid search and\n",
    "a parameter set (the DecisionTree was left as the weak learner choice) but did not achieve significants gains in performance given the\n",
    "computational cost. This leads me to believe that experimenting with the choice of weak learner would be more fruitful, but I opted to postpone\n",
    "such a study for later.\n",
    "\n",
    "* * *  \n",
    "\n",
    "__KNeighborsClassifier:__ Given an input point, __x__, it finds the k closest points to __x__ in the training set and then applies a majority\n",
    "voting scheme regarding their labels, to determine the label for __x__.\n",
    "\n",
    "__Pros:__  \n",
    "\n",
    "* Relatively fast prediction time in general, O[Dlog(N)] where D is the number attributes and N the number of training examples (D is unlikely\n",
    "  to change much in this scenario, so its really more like O[log(N)] )\n",
    "\n",
    "* Easier to conceptualize and reason about than other more sophisticated models.  \n",
    "\n",
    "__Cons:__  \n",
    "\n",
    "* Not memory efficient, since it makes predictions by directly using the data as a “model”. Must therefore keep the data stored.  \n",
    "\n",
    "__Chosen/Rejected:__ Chosen  \n",
    "\n",
    "__Reasoning:__ Upon closer reading of section 1.6.4 of Sklearn's documentation, _\"Nearest Neighbor Algorithms\"_, KNN as, I used it here, makes\n",
    "a choice of algorithm based on the data passed to fit(). The choice being between brute force, K-D tree, and Ball tree. This data set is too\n",
    "large for brute force (n = 300 >> 30) so we can consider KNN here as either K-D or Ball tree. Now, since the size of the feature space, is for\n",
    "computational purposes, D = 48 > 20 (after adding all the dummy classes) it is likely it is choosing Ball Tree. In any case its time complexity\n",
    "at prediction is O[Dlog(N)] which explains why its slower than the decision tree. Since the amount of student features is not likely to change\n",
    "much if KNN is put to practice in our scenario (suppose we choose it in the end for use of the school board), this can be consider a pro for\n",
    "this algorithm, since it is essentially logarithmic, just as the decision tree.\n",
    "Also from sklearn;  \n",
    "\n",
    "“Ball tree and KD tree query times can be greatly influenced by data structure. In general, sparser data with a smaller intrinsic\n",
    "dimensionality leads to faster query times.”\n",
    "\n",
    "If I'm understanding correctly (may very well not be) since sparsity of the data set “refers to the degree to which the data fills the\n",
    "parameter space” , then it seems to me that the data set here is somewhat sparse. The reason I say this is because when we added the dummies,\n",
    "essentially we added a lot of zero components to each student “vector”. Since the student's mother, say, cannot be partially between being a\n",
    "Teacher and Health care worker, in regard to those categorical variables, there are regions in the feature space that are empty. Because no\n",
    "vectors will ever have components that are non-zero there. If this is indeed the case, then it would also be a pro for KNN.  However if our\n",
    "training data set were to grow very large, this will come at significant memory cost.\n",
    "\n",
    "Next I try each of these models with varying training set sizes, from 50 students to 300 in increments of 50, for a total of 6 training set sizes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function makeTable\n",
    "def makeTable(clf, index_list, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    #Gathering column and row labels for the table\n",
    "    benchmarks = [\"Training time\",  \"F1 score training set\",\"Prediction time\", \"F1 score test set\"]\n",
    "    size_labels = [\"Training samples: {}\".format(len(indices)) for indices in index_list]\n",
    "    table = pd.DataFrame(columns = benchmarks, index = size_labels)\n",
    "    \n",
    "    for i, ind in enumerate(index_list): \n",
    "        #Cutting training data to len(ind) samples\n",
    "        X_tr = X_train.iloc[ind]\n",
    "        y_tr = y_train.iloc[ind]\n",
    "        #Compute benchmarks\n",
    "        t_train    = timeTraining(clf, X_tr, y_tr)\n",
    "        pred_train_set = predictAndTime(clf, X_tr)[0]\n",
    "        pred_test_set, t_test = predictAndTime(clf,X_test)  \n",
    "        \n",
    "        #fill table\n",
    "        table['Training time'][i]    = t_train\n",
    "        table['F1 score training set'][i] = F1(y_tr, pred_train_set)\n",
    "        table['Prediction time'][i]  = t_test\n",
    "        table['F1 score test set'][i] = F1(y_test, pred_test_set)\n",
    "        \n",
    "    return table \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function return a set of k unique random indices in range 0 to N\n",
    "from random import randint\n",
    "\n",
    "def getIndices(k,N):\n",
    "    ind = []\n",
    "    while(len(ind) < k):\n",
    "        i = randint(0,N)\n",
    "        if i not in ind:\n",
    "            ind.append(i)\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      Training time F1 score training set Prediction time  \\\nTraining samples: 50    0.000667095              0.892308      0.00264287   \nTraining samples: 100   0.000586033               0.87013      0.00309515   \nTraining samples: 150   0.000617027              0.877828      0.00238013   \nTraining samples: 200   0.000673056              0.875445      0.00238204   \nTraining samples: 250   0.000742197              0.887671      0.00290108   \nTraining samples: 300   0.000771046              0.882353      0.00396991   \n\n                      F1 score test set  \nTraining samples: 50           0.709677  \nTraining samples: 100          0.738462  \nTraining samples: 150          0.759124  \nTraining samples: 200           0.71875  \nTraining samples: 250          0.731343  \nTraining samples: 300           0.70229  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                      Training time F1 score training set Prediction time  \\\nTraining samples: 50    0.000967979              0.873239     0.000991106   \nTraining samples: 100    0.00193501                0.8625     0.000910997   \nTraining samples: 150    0.00334692              0.869565      0.00135398   \nTraining samples: 200    0.00415015              0.877419      0.00150704   \nTraining samples: 250    0.00604796              0.870229      0.00168085   \nTraining samples: 300    0.00822783              0.869198      0.00202703   \n\n                      F1 score test set  \nTraining samples: 50           0.765101  \nTraining samples: 100          0.781457  \nTraining samples: 150          0.783217  \nTraining samples: 200          0.767123  \nTraining samples: 250          0.767123  \nTraining samples: 300          0.758621  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                      Training time F1 score training set Prediction time  \\\nTraining samples: 50     0.00182009                     1     0.000540018   \nTraining samples: 100    0.00157309                     1     0.000306845   \nTraining samples: 150    0.00233912                     1     0.000315905   \nTraining samples: 200    0.00303698                     1     0.000295162   \nTraining samples: 250    0.00322104                     1     0.000283003   \nTraining samples: 300    0.00377703                     1     0.000267029   \n\n                      F1 score test set  \nTraining samples: 50           0.672131  \nTraining samples: 100          0.760331  \nTraining samples: 150          0.710744  \nTraining samples: 200               0.7  \nTraining samples: 250             0.784  \nTraining samples: 300          0.775194  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n"
     ]
    }
   ],
   "source": [
    "# Chosen Classifiers\n",
    "chosen_clfs = [DecisionTreeClassifier(criterion = \"entropy\"),\n",
    "        SVC(C = 1.0, kernel=\"rbf\"),\n",
    "        KNeighborsClassifier(n_neighbors = 3)]\n",
    "\n",
    "# Test Classifiers with increasing data set size\n",
    "training_sizes = [50,100,150,200,250,300]\n",
    "# Choosing random index sets for each size in training_sizes \n",
    "index_list = [getIndices(size, X_train.shape[0]-1) for size in training_sizes]\n",
    "\n",
    "for clf in chosen_clfs:\n",
    "    print clf.__class__.__name__\n",
    "    table = makeTable(clf, index_list, X_train, X_test, y_train, y_test)\n",
    "    display(table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "SVC showed consistently higher f1 test scores. The DecisionTree was very fast at predicting. KNN was very fast at training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## 5. Choosing the Best Model\n",
    "\n",
    "- Based on the experiments you performed earlier, in 1-2 paragraphs explain to the board of supervisors what single model you chose as the best\n",
    "  model. Which model is generally the most appropriate based on the available data, limited resources, cost, and performance?\n",
    "- In 1-2 paragraphs explain to the board of supervisors in layman's terms how the final model chosen is supposed to work (for example if you\n",
    "  chose a Decision Tree or Support Vector Machine, how does it make a prediction).\n",
    "- Fine-tune the model. Use Gridsearch with at least one important parameter tuned and with at least 3 settings. Use the entire training set for this.\n",
    "- What is the model's final F<sub>1</sub> score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82.1776151657\n",
      "Parameters of tuned model:  {'max_features': 'log2', 'min_samples_split': 3, 'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 6}\n",
      "f1_score and prediction time on X_test, y_test: \n",
      "0.788732394366 0.000627040863037\n",
      "------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82.1096019745\n",
      "Parameters of tuned model:  {'n_neighbors': 25, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}\n",
      "f1_score and prediction time on X_test, y_test: \n",
      "0.786666666667 0.00959801673889\n",
      "------------------\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Grid search time:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " KNeighborsClassifier\n",
      "Grid search time:"
     ]
    }
   ],
   "source": [
    "# TODO: Fine-tune your model and report the best F1 score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "scorer = make_scorer(F1)\n",
    "\n",
    "tree_param = { 'criterion': [\"entropy\", \"gini\"], 'max_features':[\"sqrt\", \"log2\"], 'max_depth': range(2,11),\n",
    "              'min_samples_split':range(2,9), 'min_samples_leaf':range(1,9) }\n",
    "\n",
    "neigh_param = {'n_neighbors' : [3,5,10,20,25,30,40], 'weights' : ['uniform', 'distance'], 'p':[1,2,3,5,10],\n",
    "              'algorithm' : ['ball_tree', 'kd_tree', 'brute']}\n",
    "\n",
    "#Perform grid Search\n",
    "def gridIt(clf, params):\n",
    "    #Grid search folds = 10, for consistency with previous computations\n",
    "    grid_clf = GridSearchCV(clf, params,\n",
    "                            scorer, n_jobs=4, cv = 10)\n",
    "    print clf.__class__.__name__\n",
    "    print \"Grid search time:\", timeTraining(grid_clf, X_train, y_train)\n",
    "    print \"Parameters of tuned model: \", grid_clf.best_params_\n",
    "    y_pred, predict_t = predictAndTime(grid_clf, X_test)\n",
    "    print \"f1_score and prediction time on X_test, y_test: \"\n",
    "    print F1(y_test, y_pred), predict_t\n",
    "    print '------------------\\n'\n",
    "    \n",
    "gridIt(KNeighborsClassifier(), neigh_param)\n",
    "gridIt(DecisionTreeClassifier(), tree_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Conclusions\n",
    "**Algorithm Selection:**  \n",
    "* * *\n",
    "The decision to use KNeighborsClassifier was mostly due to its low cost computationally. Given a battery of\n",
    "possible tuning parameters it was the only one of the algorithms that was feasably tunable given low resources.\n",
    "It performed better than other cheap alternatives like Naive Bayes, so it was reasonably\n",
    "well performing for its cost. As seen in the benchmark table in cell [82] out of the box it was outperformed only\n",
    "by the SVC, which is more costly to train. Still its improvement after tuning was only marginal. \n",
    "\n",
    "**Layman Explanation: KNeighborsClassifier**  \n",
    "* * *\n",
    "The mechanism with which our model decides whether a current student will pass or fail is very intuitive. Each student has 30 attributes\n",
    "associated with him/her. These range from basic descriptors like their age, sex, and health, to behavioral descriptors like whether they are in\n",
    "a romantic relationship, how much time they devote to study, if they have any extra curricular activities. Some of the attributes are of things\n",
    "out of there control like whether they have internet access, the size of their family, and what neighborhood they live in. What are model\n",
    "process does, is that it assigns a relevant number to every one of these attributes. Just like for example you can take a house and assign it a\n",
    "longitude, a latitude, and maybe if it sits on a hill an altitude. In the same way that information like longitude, latitude and altitude,\n",
    "alows us to decide how far away two houses are from each other, we can decide how \"far away\" two particular students are from each other. Based\n",
    "on all those attributes like free time and age and so forth. Since we have information about which students have failed and which have passed,\n",
    "our model basically answers the question; how \"close\" is this student to other students who have passed. Maybe he is \"closer\" to students who\n",
    "fail. We can choose to compare him/her to the closest _single_ student to determine how likely he is to pass or fail. Usually, however we tune\n",
    "the model to find a _group_ of students closest to him/her, maybe the closest 4 students, or maybe 10 closest students. The exact number is\n",
    "determined while tuning. Since we use students that we know either passed or failed in this group, we can determine if our student in question\n",
    "is closer to others who pass or those who fail.\n",
    "\n",
    "** Final F1 score **  \n",
    "0.787"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "name": "student_intervention_revisit.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
