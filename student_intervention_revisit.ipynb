{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Supervised Learning: Building a Student Intervention System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Objective\n",
    "\n",
    "The goal of this project is to identify students who might need early intervention. We want to predict whether a given student will pass or\n",
    "fail based on information about his life and habits. Therefore we approach this task as a classification problem with two classes, pass and fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krolik/anaconda3/envs/machiner/lib/python2.7/site-packages/matplotlib/font_manager.py:280: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Reading the data\n",
    "\n",
    "In what follows we will be working with part of the [_Student Performance Data set_](https://archive.ics.uci.edu/ml/datasets/student+performance)\n",
    "dataset from the UCI machine learning repository. It is composed of 395 data points with 30 attributes each. The 31'st attribute indicates whether\n",
    "the student passed or failed. Here is a brief description of each feature:\n",
    "\n",
    "Attributes for student-data.csv:\n",
    "\n",
    " * school - student's school (binary: \"GP\" or \"MS\")\n",
    " * sex - student's sex (binary: \"F\" - female or \"M\" - male)\n",
    " * age - student's age (numeric: from 15 to 22)\n",
    " * address - student's home address type (binary: \"U\" - urban or \"R\" - rural)\n",
    " * famsize - family size (binary: \"LE3\" - less or equal to 3 or \"GT3\" - greater than 3)\n",
    " * Pstatus - parent's cohabitation status (binary: \"T\" - living together or \"A\" - apart)\n",
    " * Medu - mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)\n",
    " * Fedu - father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)\n",
    " * Mjob - mother's job (nominal: \"teacher\", \"health\" care related, civil \"services\" (e.g. administrative or police), \"at_home\" or \"other\")\n",
    " * Fjob - father's job (nominal: \"teacher\", \"health\" care related, civil \"services\" (e.g. administrative or police), \"at_home\" or \"other\")\n",
    " * reason - reason to choose this school (nominal: close to \"home\", school \"reputation\", \"course\" preference or \"other\")\n",
    " * guardian - student's guardian (nominal: \"mother\", \"father\" or \"other\")\n",
    " * traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n",
    " * studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n",
    " * failures - number of past class failures (numeric: n if 1<=n<3, else 4)\n",
    " * schoolsup - extra educational support (binary: yes or no)\n",
    " * famsup - family educational support (binary: yes or no)\n",
    " * paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n",
    " * activities - extra-curricular activities (binary: yes or no)\n",
    " * nursery - attended nursery school (binary: yes or no)\n",
    " * higher - wants to take higher education (binary: yes or no)\n",
    " * internet - Internet access at home (binary: yes or no)\n",
    " * romantic - with a romantic relationship (binary: yes or no)\n",
    " * famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n",
    " * freetime - free time after school (numeric: from 1 - very low to 5 - very high)\n",
    " * goout - going out with friends (numeric: from 1 - very low to 5 - very high)\n",
    " * Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    " * Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    " * health - current health status (numeric: from 1 - very bad to 5 - very good)\n",
    " * absences - number of school absences (numeric: from 0 to 93)\n",
    " * passed - did the student pass the final exam (binary: yes or no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Read student data\n",
    "student_data = pd.read_csv(\"student-data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We explore the following features in the data:\n",
    "\n",
    " * Total number of students\n",
    " * Number of students who passed\n",
    " * Number of students who failed\n",
    " * Graduation rate of the class (%)\n",
    " * Number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of students: 395\n",
      "Number of students who passed: 265\n",
      "Number of students who failed: 130\n",
      "Number of features: 30\n",
      "Graduation rate of the class: 67.09%\n"
     ]
    }
   ],
   "source": [
    "n_students = student_data.shape[0]\n",
    "n_features = student_data.shape[1] - 1\n",
    "n_passed = sum([1 for y in student_data['passed'] if y == 'yes'])\n",
    "n_failed = sum([1 for n in student_data['passed'] if n == 'no'])\n",
    "grad_rate = 100.*n_passed/(n_passed + n_failed)\n",
    "\n",
    "print \"Total number of students: {}\".format(n_students)\n",
    "print \"Number of students who passed: {}\".format(n_passed)\n",
    "print \"Number of students who failed: {}\".format(n_failed)\n",
    "print \"Number of features: {}\".format(n_features)\n",
    "print \"Graduation rate of the class: {:.2f}%\".format(grad_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Preparing the Data\n",
    "In this section, we will prepare the data for modeling, training and testing.\n",
    "\n",
    "### Identify feature and target columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature column(s):-\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "Target column: passed\n"
     ]
    }
   ],
   "source": [
    "# Extract feature (X) and target (y) columns\n",
    "feature_cols = list(student_data.columns[:-1])  # all columns but last are features\n",
    "target_col = student_data.columns[-1]  # last column is the target/label\n",
    "print \"Feature column(s):-\\n{}\".format(feature_cols)\n",
    "print \"Target column: {}\".format(target_col)\n",
    "\n",
    "X_all = student_data[feature_cols]  # feature values for all students\n",
    "y_all = student_data[target_col]  # corresponding targets/labels\n",
    "# print \"\\nFeature values:-\"\n",
    "# print X_all.head()  # print the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Preprocess feature columns\n",
    "\n",
    "As you can see, there are several non-numeric columns that need to be converted. Many of them are simply `yes`/`no`, e.g. `internet`. These can\n",
    "be reasonably converted into `1`/`0` (binary) values.\n",
    "\n",
    "Other columns, like `Mjob` and `Fjob`, have more than two values, and are known as _categorical variables_. The recommended way to handle such\n",
    "a column is to create as many columns as possible values (e.g. `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc.), and assign a `1` to one of\n",
    "them and `0` to all others.\n",
    "\n",
    "These generated columns are sometimes called _dummy variables_, and we will use the\n",
    "[`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies)\n",
    "function to perform this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48):-\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "# Preprocess feature columns\n",
    "def preprocess_features(X):\n",
    "    outX = pd.DataFrame(index=X.index)  # output dataframe, initially empty\n",
    "\n",
    "    # Check each column\n",
    "    for col, col_data in X.iteritems():\n",
    "        # If data type is non-numeric, try to replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "        # Note: This should change the data type for yes/no columns to int\n",
    "\n",
    "        # If still non-numeric, convert to one or more dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix=col)  # e.g. 'school' => 'school_GP', 'school_MS'\n",
    "\n",
    "        outX = outX.join(col_data)  # collect column(s) in output dataframe\n",
    "\n",
    "    return outX\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print \"Processed feature columns ({}):-\\n{}\".format(len(X_all.columns), list(X_all.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Split data into training and test sets\n",
    "\n",
    "So far, we have converted all _categorical_ features into numeric values. In this next step, we split the data (both features and corresponding\n",
    "labels) into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 300 samples\n",
      "Test set: 95 samples\n"
     ]
    }
   ],
   "source": [
    "# First, decide how many training vs test samples you want\n",
    "num_all = student_data.shape[0]  # same as len(student_data)\n",
    "num_train = 300  # about 75% of the data\n",
    "num_test = num_all - num_train\n",
    "\n",
    "# TODO: Then, select features (X) and corresponding labels (y) for the training and test sets\n",
    "# Note: Shuffle the data or randomly select samples to avoid any bias due to ordering in the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size = .24, random_state = 0)\n",
    "\n",
    "print \"Training set: {} samples\".format(X_train.shape[0])\n",
    "print \"Test set: {} samples\".format(X_test.shape[0])\n",
    "# Note: If you need a validation set, extract it from within training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## 4. Training and Evaluating Models\n",
    "Next we perform a baseline comparison of 5 different classification models out of the box.\n",
    "\n",
    " - DecisionTreeClassifier\n",
    " - SVC\n",
    " - KNeighborsClassifier\n",
    " - GaussianNB\n",
    " - AdaBoostClassifier\n",
    "\n",
    "We fit the model to the training data, try to predict labels (for both training and test sets), and measure the F<sub>1</sub> score. Then\n",
    "repeat this process with different training set sizes (100, 200, 300), keeping test set constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* * *\n",
    "**Model Training**  \n",
    "\n",
    "Kfold cross validation can be used to get the maximum use of a small data set like the one here. To get my bearings and not to impose any\n",
    "pre-judgement, I wanted to try most of the classifiers seen in class out of the box. I excluded neural net, since its recommended use requires\n",
    "the features to be scaled (one of the disadvantages of that algorithm).  After separating the data into a training set (size 300) and test set\n",
    "(size 95), I used Kfold cross-validation on the training set with 10 folds to have a basic handle on how the models were performing on\n",
    "average. The result of this can be seen in the table below. The decision tree trails all others in its f1 test score, while scoring perfectly\n",
    "on the training set (which no other does) so it seems to be over-fitting.  The SVC tops all others with an average test f1 of 0.808. KNN\n",
    "doesn't trail far with 0.781. Naive Bayes and AdaBoost are pretty much tied with test f1's of 0.768 and 0.767 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "import time\n",
    "from IPython.display import display, HTML, Image, display_pretty\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Return the classifier's training time\n",
    "def timeTraining(clf, X_train, y_train):\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    return (end - start)\n",
    "\n",
    "# Return the classifier's predictions and prediction time\n",
    "def predictAndTime(clf, features):\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    return y_pred, (end - start)\n",
    "\n",
    "# Return the f1 score for the target values and predictions\n",
    "def F1(target, prediction):\n",
    "    return f1_score(target.values, prediction, pos_label='yes')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getIndices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4d6bc9bb0f1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtraining_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Choosing random index sets for each size in training_sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mindex_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetIndices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_sizes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchosen_clfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'getIndices' is not defined"
     ]
    }
   ],
   "source": [
    "# Chosen Classifiers\n",
    "chosen_clfs = [DecisionTreeClassifier(criterion = \"entropy\"),\n",
    "        SVC(C = 1.0, kernel=\"rbf\"),\n",
    "        KNeighborsClassifier(n_neighbors = 3)]\n",
    "\n",
    "# Test Classifiers with increasing data set size\n",
    "training_sizes = [50,100,150,200,250,300]\n",
    "# Choosing random index sets for each size in training_sizes \n",
    "index_list = [getIndices(size, X_train.shape[0]-1) for size in training_sizes]\n",
    "\n",
    "for clf in chosen_clfs:\n",
    "    print clf.__class__.__name__\n",
    "    table = makeTable(clf, index_list, X_train, X_test, y_train, y_test)\n",
    "    display_pretty(table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "SVC showed consistently higher f1 test scores. The DecisionTree was very fast at predicting. KNN was very fast at training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## 5. Choosing the Best Model\n",
    "\n",
    "- Based on the experiments you performed earlier, in 1-2 paragraphs explain to the board of supervisors what single model you chose as the best\n",
    "  model. Which model is generally the most appropriate based on the available data, limited resources, cost, and performance?\n",
    "- In 1-2 paragraphs explain to the board of supervisors in layman's terms how the final model chosen is supposed to work (for example if you\n",
    "  chose a Decision Tree or Support Vector Machine, how does it make a prediction).\n",
    "- Fine-tune the model. Use Gridsearch with at least one important parameter tuned and with at least 3 settings. Use the entire training set for this.\n",
    "- What is the model's final F<sub>1</sub> score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90.4000577927\n",
      "Parameters of tuned model:  {'max_features': 'sqrt', 'min_samples_split': 6, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_leaf': 2}\n",
      "f1_score and prediction time on X_test, y_test: \n",
      "0.778523489933 0.00148892402649\n",
      "------------------\n",
      "\n",
      " 86.8100130558\n",
      "Parameters of tuned model:  {'n_neighbors': 25, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}\n",
      "f1_score and prediction time on X_test, y_test: \n",
      "0.786666666667 0.00957107543945\n",
      "------------------\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Grid search time:KNeighborsClassifier\n",
      "Grid search time:"
     ]
    }
   ],
   "source": [
    "# TODO: Fine-tune your model and report the best F1 score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "scorer = make_scorer(F1)\n",
    "\n",
    "tree_param = { 'criterion': [\"entropy\", \"gini\"], 'max_features':[\"sqrt\", \"log2\"], 'max_depth': range(2,11),\n",
    "              'min_samples_split':range(2,9), 'min_samples_leaf':range(1,9) }\n",
    "\n",
    "neigh_param = {'n_neighbors' : [3,5,10,20,25,30,40], 'weights' : ['uniform', 'distance'], 'p':[1,2,3,5,10],\n",
    "              'algorithm' : ['ball_tree', 'kd_tree', 'brute']}\n",
    "\n",
    "#Perform grid Search\n",
    "def gridIt(clf, params):\n",
    "    #Grid search folds = 10, for consistency with previous computations\n",
    "    grid_clf = GridSearchCV(clf, params,\n",
    "                            scorer, n_jobs=4, cv = 10)\n",
    "    print clf.__class__.__name__\n",
    "    print \"Grid search time:\", timeTraining(grid_clf, X_train, y_train)\n",
    "    print \"Parameters of tuned model: \", grid_clf.best_params_\n",
    "    y_pred, predict_t = predictAndTime(grid_clf, X_test)\n",
    "    print \"f1_score and prediction time on X_test, y_test: \"\n",
    "    print F1(y_test, y_pred), predict_t\n",
    "    print '------------------\\n'\n",
    "    \n",
    "gridIt(KNeighborsClassifier(), neigh_param)\n",
    "gridIt(DecisionTreeClassifier(), tree_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pydotplus",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-15f78f30586a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m dot_data = tree_classifier.export_graphviz(clf, out_file=None, \n\u001b[1;32m      9\u001b[0m                      \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named pydotplus"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.778523489933 0.000586986541748\n"
     ]
    }
   ],
   "source": [
    "tree_classifier = DecisionTreeClassifier(max_features='sqrt', min_samples_split=6, criterion='entropy', max_depth=2, min_samples_leaf=2)\n",
    "tree_classifier.fit(X_train, y_train)\n",
    "y_pred, predict_t = predictAndTime(tree_classifier, X_test)\n",
    "print F1(y_test, y_pred), predict_t\n",
    "\n",
    "\n",
    "import pydotplus\n",
    "dot_data = tree_classifier.export_graphviz(clf, out_file=None, \n",
    "                     feature_names=iris.feature_names,  \n",
    "                     class_names=iris.target_names,  \n",
    "                     filled=True, rounded=True,  \n",
    "                     special_characters=True)\n",
    "                     \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "\n",
    "Image(graph.create_png())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Conclusions\n",
    "**Algorithm Selection:**  \n",
    "* * *\n",
    "The decision to use KNeighborsClassifier was mostly due to its low cost computationally. Given a battery of\n",
    "possible tuning parameters it was the only one of the algorithms that was feasably tunable given low resources.\n",
    "It performed better than other cheap alternatives like Naive Bayes, so it was reasonably\n",
    "well performing for its cost. As seen in the benchmark table in cell [82] out of the box it was outperformed only\n",
    "by the SVC, which is more costly to train. Still its improvement after tuning was only marginal. \n",
    "\n",
    "**Layman Explanation: KNeighborsClassifier**  \n",
    "* * *\n",
    "The mechanism with which our model decides whether a current student will pass or fail is very intuitive. Each student has 30 attributes\n",
    "associated with him/her. These range from basic descriptors like their age, sex, and health, to behavioral descriptors like whether they are in\n",
    "a romantic relationship, how much time they devote to study, if they have any extra curricular activities. Some of the attributes are of things\n",
    "out of there control like whether they have internet access, the size of their family, and what neighborhood they live in. What are model\n",
    "process does, is that it assigns a relevant number to every one of these attributes. Just like for example you can take a house and assign it a\n",
    "longitude, a latitude, and maybe if it sits on a hill an altitude. In the same way that information like longitude, latitude and altitude,\n",
    "alows us to decide how far away two houses are from each other, we can decide how \"far away\" two particular students are from each other. Based\n",
    "on all those attributes like free time and age and so forth. Since we have information about which students have failed and which have passed,\n",
    "our model basically answers the question; how \"close\" is this student to other students who have passed. Maybe he is \"closer\" to students who\n",
    "fail. We can choose to compare him/her to the closest _single_ student to determine how likely he is to pass or fail. Usually, however we tune\n",
    "the model to find a _group_ of students closest to him/her, maybe the closest 4 students, or maybe 10 closest students. The exact number is\n",
    "determined while tuning. Since we use students that we know either passed or failed in this group, we can determine if our student in question\n",
    "is closer to others who pass or those who fail.\n",
    "\n",
    "** Final F1 score **  \n",
    "0.787"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "name": "student_intervention_revisit.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
